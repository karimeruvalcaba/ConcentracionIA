{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf06b529",
   "metadata": {
    "id": "cf06b529"
   },
   "source": [
    "\n",
    "# **Clasificación de Texto con Zero-shot y Few-shot usando **Chat Completions** (OpenAI)**  \n",
    "\n",
    "\n",
    "> **Objetivo.** Este cuaderno guía paso a paso cómo construir un pipeline reproducible de clasificación de texto con **LLMs** usando la ruta **simple** basada en `client.chat.completions.create(...)` y **parseo de JSON**. Se incluye control de **costos** vía límite de llamadas `MAX_CALLS`, submuestreo `N_SAMPLE`, y evaluación (accuracy, macro-F1, matriz de confusión). Se siguen principios básicos de **prompt engineering**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0cabe",
   "metadata": {
    "id": "01b0cabe"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 0) Instalación de dependencias (si está en Colab)\n",
    "#    *Descomentar si se necesitan instalar paquetes en la sesión.*\n",
    "# ============================================================\n",
    "\n",
    "!pip -q install \"openai==1.*\" scikit-learn pandas numpy matplotlib tqdm python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd77d1",
   "metadata": {
    "id": "e5fd77d1"
   },
   "source": [
    "\n",
    "## 1) Preparación del entorno y conexión a Google Drive (Colab)\n",
    "\n",
    "Esta sección prepara el entorno con importaciones y, si el cuaderno corre en **Colab**, monta **Google Drive**. Así se puede leer el **mismo archivo de datos** también desde computador local.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4326b",
   "metadata": {
    "id": "b1a4326b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import getpass\n",
    "import os, sys, json, textwrap, time, math, random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Su6FH0xgiXAl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Su6FH0xgiXAl",
    "outputId": "85f3bd03-a3c5-40a5-e80f-222eda366673"
   },
   "outputs": [],
   "source": [
    "# Detección de entorno Colab y montaje de Drive\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/drive')\n",
    "    print(\"✔ Drive montado en /drive\")\n",
    "else:\n",
    "    print(\"ℹ No se detectó Colab; se usarán rutas locales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12102be",
   "metadata": {
    "id": "f12102be"
   },
   "source": [
    "\n",
    "## 2) API Key de OpenAI y configuración del cliente\n",
    "\n",
    "- Por seguridad, se recomienda **no** hardcodear credenciales.\n",
    "- En Colab, se sugiere ingresar el token mediante `getpass` para la sesión.\n",
    "- Utilizamos **Chat Completions** con salida JSON.\n",
    "\n",
    "> Si la clave es de **Proyecto** (formato `sk-proj-...`), el uso se verá en el **Dashboard del Proyecto** (ícono de la llave en Colab) no en el espacio personal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f1453",
   "metadata": {
    "id": "9e5f1453"
   },
   "outputs": [],
   "source": [
    "# Ingreso interactivo si falta la variable de entorno.\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    if IN_COLAB:\n",
    "        print(\"Introduzca su OPENAI_API_KEY (no se almacena en disco):\")\n",
    "        os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "        # Inicializa cliente (toma OPENAI_API_KEY del entorno)\n",
    "        client = OpenAI()\n",
    "    else:\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        # Initialize the client\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        print(\"⚠ Establezca OPENAI_API_KEY en su entorno para continuar.\")\n",
    "\n",
    "if client:\n",
    "    print(\"success\")\n",
    "\n",
    "# Modelo por defecto (ajustable según coste/capacidad)\n",
    "MODEL_NAME = \"gpt-4o-mini\"  # Alternativas: \"gpt-4o\", \"gpt-4.1-mini\", etc.\n",
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8b9514",
   "metadata": {
    "id": "ba8b9514"
   },
   "source": [
    "\n",
    "## 3) Rutas y configuración general\n",
    "\n",
    "- Ajustar `DATA_PATH` a la **misma ruta del dataset** que usa el pipeline clásico.\n",
    "- `OUTPUT_DIR` se usa para guardar artefactos (predicciones, figuras) en Drive.\n",
    "- `N_SAMPLE=30` permite evaluar un subconjunto para **limitar costos**.\n",
    "- `MAX_CALLS` controla el **número máximo** de llamadas a la API durante la sesión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pLV4ySucjBUY",
   "metadata": {
    "id": "pLV4ySucjBUY"
   },
   "outputs": [],
   "source": [
    "# ======= CONFIGURACIÓN DE RUTAS =======\n",
    "# Ajuste DATA_PATH a la misma ubicación de su dataset en Drive (o ruta local si no usa Colab).\n",
    "\n",
    "path = '/drive/My Drive/Colab Notebooks/infotracer_Estancia/'\n",
    "if not os.path.exists(path):\n",
    "    path = r\"C:\\Users\\abdel\\Downloads\\concentracionIA\"\n",
    "    \n",
    "input_file = 'data_labelled/youtube-senti-labelled.xlsx' if os.path.exists('data_labelled/youtube-senti-labelled.xlsx') else \"youtube-senti-labelled-short(Sheet1).csv\"\n",
    "\n",
    "output_dir = 'results_llms'\n",
    "\n",
    "DATA_PATH = path + input_file  if IN_COLAB else './' + input_file\n",
    "OUTPUT_DIR = path + output_dir if IN_COLAB else './' + output_dir\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "Dm-nQdN2-cqp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dm-nQdN2-cqp",
    "outputId": "8ad0660b-4cc5-441b-fd3b-2a7228378111"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a7cdc89",
   "metadata": {
    "id": "4a7cdc89"
   },
   "outputs": [],
   "source": [
    "# ======= CONTROL DE COSTOS =======\n",
    "N_SAMPLE = 15     # número de instancias de test para pruebas rápidas\n",
    "MAX_CALLS = 80    # tope de llamadas a la API (ajuste según presupuesto)\n",
    "API_CALLS_USED = 0\n",
    "\n",
    "def check_quota():\n",
    "    \"\"\"Verifica y consume 1 crédito de llamada a la API.\"\"\"\n",
    "    global API_CALLS_USED\n",
    "    if API_CALLS_USED >= MAX_CALLS:\n",
    "        raise RuntimeError(\n",
    "            f\"Se alcanzó el límite de {MAX_CALLS} llamadas a la API. \"\n",
    "            f\"Aumente MAX_CALLS o reduzca el dataset de prueba (N_SAMPLE).\"\n",
    "        )\n",
    "    API_CALLS_USED += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa28e5",
   "metadata": {
    "id": "49aa28e5"
   },
   "source": [
    "\n",
    "## 4) Lectura del dataset y EDA mínima\n",
    "\n",
    "Asumimos que existe una columna de **texto** y una de **etiqueta**. Se implementa una heurística para detectar nombres comunes. Si las columnas con las que se está trabajando algún archivo difieren, se recomienda **ajustar manualmente** `TEXT_COL` y `LABEL_COL` tras cargar el dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b997ba13",
   "metadata": {
    "id": "b997ba13"
   },
   "outputs": [],
   "source": [
    "\n",
    "TEXT_CANDIDATES  = [\"text\",\"texto\",\"review\",\"content\",\"sentence\",\"tweet\",\"document\"]\n",
    "LABEL_CANDIDATES = [\"label\",\"labels\",\"etiqueta\",\"etiquetas\",\"sentiment\",\"Sentiment\",\"target\",\"y\"]\n",
    "\n",
    "def load_dataset(path: str, sheet_name=0):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"No se encontró el archivo en: {p}\")\n",
    "\n",
    "    suffix = p.suffix.lower()\n",
    "\n",
    "    if suffix in [\".csv\", \".tsv\"]:\n",
    "        sep = \",\" if suffix == \".csv\" else \"\\t\"\n",
    "        encodings_to_try = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\"]\n",
    "        last_err = None\n",
    "        for enc in encodings_to_try:\n",
    "            try:\n",
    "                return pd.read_csv(p, sep=sep, encoding=enc)\n",
    "            except UnicodeDecodeError as e:\n",
    "                last_err = e\n",
    "                continue\n",
    "        # último recurso: reemplaza caracteres ilegales (pandas ≥ 2.0)\n",
    "        try:\n",
    "            return pd.read_csv(p, sep=sep, encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "        except TypeError:\n",
    "            # si tu pandas no acepta encoding_errors\n",
    "            raise last_err\n",
    "\n",
    "    elif suffix in [\".parquet\", \".pq\"]:\n",
    "        return pd.read_parquet(p)\n",
    "\n",
    "    elif suffix in [\".xlsx\", \".xls\"]:\n",
    "        # .xlsx usa openpyxl; .xls requiere xlrd (<2.0) instalado\n",
    "        engine = \"openpyxl\" if suffix == \".xlsx\" else None\n",
    "        return pd.read_excel(p, sheet_name=sheet_name, engine=engine)\n",
    "\n",
    "    else:\n",
    "        # Intento por defecto: CSV con detección de delimitador\n",
    "        encodings_to_try = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\"]\n",
    "        last_err = None\n",
    "        for enc in encodings_to_try:\n",
    "            try:\n",
    "                return pd.read_csv(p, sep=None, engine=\"python\", encoding=enc)\n",
    "            except UnicodeDecodeError as e:\n",
    "                last_err = e\n",
    "                continue\n",
    "        try:\n",
    "            return pd.read_csv(p, sep=None, engine=\"python\", encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "        except TypeError:\n",
    "            raise last_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "HMDW48VRxx08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "HMDW48VRxx08",
    "outputId": "696a8197-d8c7-4047-a2ac-39b41f04360e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño bruto: 999\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(DATA_PATH).copy()\n",
    "print(\"Tamaño bruto:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97e0fb8a",
   "metadata": {
    "id": "97e0fb8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño bruto: 999\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset(DATA_PATH).copy()\n",
    "print(\"Tamaño bruto:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbvRJ0p3x2Kp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "dbvRJ0p3x2Kp",
    "outputId": "7217b327-9c5f-4edc-bd02-de805e9ccc68"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "JUdMjxERx2xQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "JUdMjxERx2xQ",
    "outputId": "cc0a1131-7e8a-419b-f44e-c9ae335893db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#claudiasheinbaum __ Después de terminar el ar...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>??EN VIVO Mario Delgado. Conferencia de prensa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>??NO LO QUIEREN DE FISCAL! EMBESTIDA CONTRA ZA...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTO LE CONTESTA A LILLY TÉLLEZ#noticias #shor...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Claudia Sheinbaum recuerda La Linea 12 del MET...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment\n",
       "0  #claudiasheinbaum __ Después de terminar el ar...  positive\n",
       "1  ??EN VIVO Mario Delgado. Conferencia de prensa...   neutral\n",
       "2  ??NO LO QUIEREN DE FISCAL! EMBESTIDA CONTRA ZA...  negative\n",
       "3  ESTO LE CONTESTA A LILLY TÉLLEZ#noticias #shor...  negative\n",
       "4  Claudia Sheinbaum recuerda La Linea 12 del MET...  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inferencia de columnas\n",
    "TEXT_COL = next((c for c in TEXT_CANDIDATES if c in df.columns), None)\n",
    "LABEL_COL = next((c for c in LABEL_CANDIDATES if c in df.columns), None)\n",
    "\n",
    "if TEXT_COL is None or LABEL_COL is None:\n",
    "    raise ValueError(\n",
    "        f\"No se detectaron columnas esperadas.\\n\"\n",
    "        f\"Candidatos texto: {TEXT_CANDIDATES}\\n\"\n",
    "        f\"Candidatos etiqueta: {LABEL_CANDIDATES}\\n\"\n",
    "        f\"Columnas disponibles: {list(df.columns)}\"\n",
    "    )\n",
    "\n",
    "df = df[[TEXT_COL, LABEL_COL]].dropna().reset_index(drop=True)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "VS5581kNx5rE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VS5581kNx5rE",
    "outputId": "49711d5c-be8d-45af-dfaa-39ba02841978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de etiquetas:\n",
      "Sentiment\n",
      "negative    63\n",
      "neutral     30\n",
      "positive     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribución de etiquetas:\")\n",
    "print(df[LABEL_COL].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442eefde",
   "metadata": {
    "id": "442eefde"
   },
   "source": [
    "\n",
    "## 5) Partición Train/Test\n",
    "\n",
    "Se separa un conjunto de **entrenamiento** (para seleccionar ejemplos Few-shot) y un conjunto **test** (para evaluación). En **Zero-shot**, el modelo no ve ejemplos; en **Few-shot**, se inyectan ejemplos en el prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f60f8cad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f60f8cad",
    "outputId": "3311f8ac-4852-4cbf-cf04-99f534a58459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas detectadas: ['negative', 'neutral', 'positive']\n",
      "Tamaño train: 70 | Tamaño test: 30\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    df, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=df[LABEL_COL]\n",
    ")\n",
    "\n",
    "labels = sorted(df[LABEL_COL].unique().tolist())\n",
    "print(\"Etiquetas detectadas:\", labels)\n",
    "print(f\"Tamaño train: {len(train_df)} | Tamaño test: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c6ce6",
   "metadata": {
    "id": "5b8c6ce6"
   },
   "source": [
    "\n",
    "## 6) Submuestreo para pruebas rápidas (control de costos)\n",
    "\n",
    "Para evitar un consumo elevado durante la etapa de prototipado, se seleccionan **30 instancias aleatorias** del conjunto de test. Este valor puede ajustarse en `N_SAMPLE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c527374",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "2c527374",
    "outputId": "b882913a-b139-4ff0-8573-e7f11acf5ba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 15 instancias para pruebas rápidas (de 30 totales).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LA PATIZA DE SU VIDA??SIN MIEDO AL CONTEO DE V...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLAUDIA ES LA CONTINUIDAD DE LA 4T #claudiashe...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MÁYNEZ se BURLA de la OPOSICIÓN ???? tras RENU...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#claudiasheinbaum #mexicanos #mexico #cuartatr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Segundo Debate Presidencial: Empleo e inflació...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text Sentiment\n",
       "0  LA PATIZA DE SU VIDA??SIN MIEDO AL CONTEO DE V...  positive\n",
       "1  CLAUDIA ES LA CONTINUIDAD DE LA 4T #claudiashe...   neutral\n",
       "2  MÁYNEZ se BURLA de la OPOSICIÓN ???? tras RENU...  negative\n",
       "3  #claudiasheinbaum #mexicanos #mexico #cuartatr...  negative\n",
       "4  Segundo Debate Presidencial: Empleo e inflació...  negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Submuestra de test\n",
    "if N_SAMPLE is not None and N_SAMPLE > 0:\n",
    "    test_sample = test_df.sample(n=min(N_SAMPLE, len(test_df)), random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "else:\n",
    "    test_sample = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Usando {len(test_sample)} instancias para pruebas rápidas (de {len(test_df)} totales).\")\n",
    "display(test_sample.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d98e0a",
   "metadata": {
    "id": "d3d98e0a"
   },
   "source": [
    "\n",
    "## 7) Taxonomía de etiquetas y políticas de fuera de dominio (opcional)\n",
    "\n",
    "- Se puede trabajar un **diccionario canónico** de descripciones por etiqueta para mejorar la desambiguación. Es decir, explicar lo que significa cada etiqueta.\n",
    "- Puede habilitarse una etiqueta **OUT_OF_DOMAIN** cuando el texto no encaje en ninguna clase.\n",
    "\n",
    "Estas definiciones se incorporan al **system prompt**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b5658da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b5658da",
    "outputId": "d81d5610-7b2f-4c03-ae28-0c1cdca7473b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de etiquetas permitido: ['negative', 'neutral', 'positive']\n"
     ]
    }
   ],
   "source": [
    "# Descripciones canónicas por etiqueta:\n",
    "LABEL_DESCRIPTIONS = {lab: f\"Definición breve y canónica de la clase '{lab}'.\" for lab in labels}\n",
    "\n",
    "ALLOW_OOD = False\n",
    "OOD_LABEL = \"OUT_OF_DOMAIN\"\n",
    "if ALLOW_OOD and OOD_LABEL not in labels:\n",
    "    labels_plus = labels + [OOD_LABEL]\n",
    "else:\n",
    "    labels_plus = labels[:]\n",
    "\n",
    "print(\"Conjunto de etiquetas permitido:\", labels_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f384954",
   "metadata": {
    "id": "0f384954"
   },
   "source": [
    "\n",
    "## 8) Prompt Engineering: **System prompt** y **User prompt**\n",
    "\n",
    "**Principios didácticos** que guían este diseño:\n",
    "- Instrucciones claras y delimitadas.\n",
    "- Lista explícita de **etiquetas permitidas**.\n",
    "- Formato de salida **JSON** con claves esperadas: `label`, `confidence`, `explanation`.\n",
    "- **Temperature=0** para priorizar consistencia.\n",
    "\n",
    "> En Few-shot, se agregan **k ejemplos** al *system prompt* bajo una sección de contexto. Alternativamente, también se puede hacer *few-shot* con pares de mensajes (`user`/`assistant`) para cada ejemplo; aquí se trabaja el esquema con sección de ejemplos por simplicidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f218c251",
   "metadata": {
    "id": "f218c251"
   },
   "outputs": [],
   "source": [
    "def build_system_prompt(label_desc: dict, labels_allowed: list, allow_ood: bool) -> str:\n",
    "    label_block = \"\\n\".join([f\"- {k}: {v}\" for k, v in label_desc.items()])\n",
    "    extra_ood = (\n",
    "        f\"\\n- {OOD_LABEL}: Use esta etiqueta únicamente si el texto no encaja en ninguna clase anterior.\"\n",
    "        if allow_ood else \"\"\n",
    "    )\n",
    "    system = f\"\"\"\n",
    "Asume el rol de un experto en análisis de sentimientos de comentarios en redes sociales, centrado en el contexto político mexicano.\n",
    "\n",
    "Eres un asistente de **clasificación de texto**. Tu tarea es asignar **una única etiqueta de sentimiento** al texto de entrada, seleccionándola de la lista permitida.\n",
    "Devuelve la salida **exclusivamente** en formato JSON válido con las claves:\n",
    "\n",
    "- \"sentiment\": etiqueta predicha (string; obligatoria; debe pertenecer al conjunto permitido).\n",
    "- \"confidence_0_5\": número en [0,5] que represente tu certeza subjetiva sobre la etiqueta predicha.\n",
    "- \"justification\": un objeto que contenga:\n",
    "  - \"keywords\": lista de 2 a 4 palabras clave que influyen en tu decisión.\n",
    "  - \"spans\": lista de fragmentos textuales relevantes del post.\n",
    "  - \"explanation\": explicación concisa sobre tu justificativa para tu predicción (2-3 frases).\n",
    "\n",
    "**Conjunto de etiquetas permitido** ({len(labels_allowed)}):\n",
    "{label_block}{extra_ood}\n",
    "\n",
    "**Reglas de decisión**\n",
    "- Basándote en el **sentimiento general** del texto, escoge **una sola** etiqueta del conjunto permitido que mejor lo represente.\n",
    "- Utiliza las descripciones de las etiquetas proporcionadas para guiar tu decisión.\n",
    "- Si no encuentras evidencia suficiente de un sentimiento claro, el texto es ambiguo o está completamente fuera del dominio de los sentimientos definidos (solo si se habilitó '{OOD_LABEL}'), utiliza '{OOD_LABEL}'.\n",
    "**Formato de salida obligatorio**\n",
    "Devuelve **solo** JSON, sin prosa adicional, p. ej.:\n",
    "\n",
    "{{\n",
    "    \"sentiment\": \"negative\",\n",
    "  \"confidence_0_5\": 4,\n",
    "  \"justification\": {{\n",
    "    \"keywords\": [\"indignante\", \"corrupción\"],\n",
    "    \"spans\": [\"¡Qué indignante!\", \"habla de corrupción\"],\n",
    "    \"explanation\": \"El texto expresa claramente indignación y menciona corrupción, lo que indica un sentimiento negativo.\"\n",
    "  }}\n",
    "}}\n",
    "\"\"\".strip()\n",
    "    return system\n",
    "\n",
    "def build_user_prompt(texto: str) -> str:\n",
    "    user = f\"\"\"\n",
    "Clasifica el siguiente documento y responde **exclusivamente** con el JSON solicitado:\n",
    "\n",
    "```texto\n",
    "{texto}\n",
    "```\n",
    "\"\"\".strip()\n",
    "    return user\n",
    "\n",
    "SYSTEM_PROMPT = build_system_prompt(LABEL_DESCRIPTIONS, labels_plus, ALLOW_OOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9a1a39",
   "metadata": {
    "id": "ad9a1a39"
   },
   "source": [
    "\n",
    "## 9) Funciones auxiliares: parseo robusto de JSON y cuota de llamadas\n",
    "\n",
    "- `parse_json_strict`: intenta decodificar el JSON; hace limpiezas mínimas si hay backticks u otros delimitadores.\n",
    "- `check_quota`: asegura que no se exceda `MAX_CALLS`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "762fe62c",
   "metadata": {
    "id": "762fe62c"
   },
   "outputs": [],
   "source": [
    "def parse_json_strict(raw: str) -> dict:\n",
    "    \"\"\"\n",
    "    Intenta parsear JSON desde un string.\n",
    "    - Elimina backticks y espacios innecesarios.\n",
    "    - Lanza ValueError si no logra decodificar.\n",
    "    \"\"\"\n",
    "    if raw is None:\n",
    "        raise ValueError(\"Respuesta vacía.\")\n",
    "    cleaned = raw.strip()\n",
    "    # Limpiezas frecuentes (bloques con ```json ... ```)\n",
    "    if cleaned.startswith(\"```\"):\n",
    "        cleaned = cleaned.strip(\"`\")\n",
    "        # Si queda un prefijo 'json\\n', eliminarlo\n",
    "        if cleaned.lower().startswith(\"json\"):\n",
    "            cleaned = cleaned[4:].lstrip()\n",
    "    # Intento de parseo directo\n",
    "    return json.loads(cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7ae41",
   "metadata": {
    "id": "afb7ae41"
   },
   "source": [
    "\n",
    "## 10) Llamadas a la API (Chat Completions) — Zero-shot y Few-shot\n",
    "\n",
    "- Se usa `response_format={\"type\":\"json_object\"}` para **favorecer** que la salida sea JSON válido.\n",
    "- En **Zero-shot**, el *system prompt* es el base.\n",
    "- En **Few-shot**, se **inyecta** una sección de ejemplos al final del *system prompt*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c73a4c3d",
   "metadata": {
    "id": "c73a4c3d"
   },
   "outputs": [],
   "source": [
    "def llm_classify_one_zero(texto: str,\n",
    "                          temperature: float = 0.0,\n",
    "                          model: str = MODEL_NAME,\n",
    "                          max_retries: int = 3,\n",
    "                          sleep_base: float = 1.5):\n",
    "    \"\"\"\n",
    "    Clasifica un texto sin ejemplos (Zero-shot) usando Chat Completions.\n",
    "    Devuelve un dict con {label, confidence_0_5, explanation, raw}.\n",
    "    \"\"\"\n",
    "    user_prompt = build_user_prompt(texto)\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            check_quota()\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={\"type\": \"json_object\"}  # favorece JSON válido\n",
    "            )\n",
    "            raw = resp.choices[0].message.content\n",
    "            data = parse_json_strict(raw)\n",
    "\n",
    "            label = data.get(\"label\")\n",
    "            if label not in labels_plus:\n",
    "                label = OOD_LABEL if ALLOW_OOD else random.choice(labels_plus)\n",
    "            return {\n",
    "                \"label\": label,\n",
    "                \"confidence_0_5\": data.get(\"confidence_0_5\"),\n",
    "                \"justification\": data.get(\"justification\", {\n",
    "                    \"keywords\": [],\n",
    "                    \"spans\": [],\n",
    "                    \"explanation\": data.get(\"explanation\", \"\")\n",
    "                }),\n",
    "                \"raw\": data\n",
    "            }\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"[llm_classify_one_zero] intento {attempt+1} falló: {e}\")\n",
    "            time.sleep(sleep_base * (2 ** attempt))\n",
    "\n",
    "    # Falla definitiva\n",
    "    return {\n",
    "        \"label\": OOD_LABEL if ALLOW_OOD else random.choice(labels_plus),\n",
    "        \"confidence_0_5\": None,\n",
    "        \"justification\": {\n",
    "            \"keywords\": f\"fallback: {last_err}\",\n",
    "            \"spans\": f\"fallback: {last_err}\",\n",
    "            \"explanation\": f\"fallback: {last_err}\"\n",
    "        },\n",
    "        \"raw\": None,\n",
    "    }\n",
    "\n",
    "\n",
    "def sample_few_shot_examples(train: pd.DataFrame, label_col: str, text_col: str,\n",
    "                             k: int, seed: int=42):\n",
    "    \"\"\"\n",
    "    Selecciona k ejemplos por clase desde train para Few-shot.\n",
    "    Estrategia: muestreo estratificado simple.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    for lab in labels:\n",
    "        subset = train[train[label_col]==lab]\n",
    "        kk = min(k, len(subset))\n",
    "        if kk == 0:\n",
    "            continue\n",
    "        exs = subset.sample(n=kk, random_state=seed)\n",
    "        for _, row in exs.iterrows():\n",
    "            examples.append({\"label\": lab, \"text\": str(row[text_col])})\n",
    "    return examples\n",
    "\n",
    "\n",
    "def build_few_shot_system_prompt(base_system: str, examples: list) -> str:\n",
    "    \"\"\"\n",
    "    Agrega una sección con ejemplos al final del system prompt.\n",
    "    \"\"\"\n",
    "    parts = [base_system, \"\\n=== EJEMPLOS DE CONTEXTO (Few-shot) ===\"]\n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        parts.append(\n",
    "            f\"\\nEjemplo {i}:\\n\"\n",
    "            f\"Texto:\\n\\\"\\\"\\\"\\n{ex['text']}\\n\\\"\\\"\\\"\\n\"\n",
    "            f\"Etiqueta esperada: {ex['label']}\"\n",
    "        )\n",
    "    parts.append(\"\\n=== FIN DE EJEMPLOS ===\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "def llm_classify_one_fewshot(texto: str, examples: list,\n",
    "                             temperature: float = 0.0, model: str = MODEL_NAME,\n",
    "                             max_retries: int = 3, sleep_base: float = 1.5):\n",
    "    \"\"\"\n",
    "    Clasifica un texto **con** ejemplos (Few-shot) inyectados en el system prompt.\n",
    "    Devuelve una etiqueta.\n",
    "    \"\"\"\n",
    "    user_prompt = build_user_prompt(texto)\n",
    "    sys_prompt_fs = build_few_shot_system_prompt(SYSTEM_PROMPT, examples)\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            check_quota()\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": sys_prompt_fs},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            raw = resp.choices[0].message.content\n",
    "            data = parse_json_strict(raw)\n",
    "            label = data.get(\"label\")\n",
    "            if label not in labels_plus:\n",
    "                label = OOD_LABEL if ALLOW_OOD else random.choice(labels_plus)\n",
    "            return label\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"[llm_classify_one_fewshot] intento {attempt+1} falló: {e}\")\n",
    "            time.sleep(sleep_base * (2 ** attempt))\n",
    "\n",
    "    return OOD_LABEL if ALLOW_OOD else random.choice(labels_plus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad328d7",
   "metadata": {
    "id": "8ad328d7"
   },
   "source": [
    "\n",
    "## 11) Inferencia por lotes y métricas de evaluación\n",
    "\n",
    "Se implementan funciones para ejecutar Zero-shot y Few-shot sobre el subconjunto de prueba y calcular métricas clásicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ea184",
   "metadata": {
    "id": "dd1ea184"
   },
   "outputs": [],
   "source": [
    "def run_zero_shot(df_in: pd.DataFrame, text_col: str, label_col: str) -> pd.DataFrame:\n",
    "    preds = []\n",
    "    for txt in tqdm(df_in[text_col].tolist(), desc=\"Zero-shot inferencia\"):\n",
    "        out = llm_classify_one_zero(txt, temperature=0.0, model=MODEL_NAME)\n",
    "        preds.append(out[\"label\"])\n",
    "    out_df = df_in.copy()\n",
    "    out_df[\"pred_zero_shot\"] = preds\n",
    "    return out_df\n",
    "\n",
    "\n",
    "def run_few_shot(train_df: pd.DataFrame, test_df: pd.DataFrame,\n",
    "                 text_col: str, label_col: str, k_shots: int = 3) -> pd.DataFrame:\n",
    "    examples = sample_few_shot_examples(train_df, label_col, text_col, k=k_shots, seed=RANDOM_SEED)\n",
    "    preds = []\n",
    "    for txt in tqdm(test_df[text_col].tolist(), desc=f\"Few-shot (k={k_shots}) inferencia\"):\n",
    "        preds.append(llm_classify_one_fewshot(txt, examples, temperature=0.0, model=MODEL_NAME))\n",
    "    out_df = test_df.copy()\n",
    "    out_df[f\"pred_few_shot_k{k_shots}\"] = preds\n",
    "    return out_df\n",
    "\n",
    "\n",
    "def plot_confusion(cm: np.ndarray, labels_axis: list, title: str):\n",
    "    fig = plt.figure(figsize=(6,5))\n",
    "    plt.imshow(cm, interpolation='nearest')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicción\"); plt.ylabel(\"Verdadero\")\n",
    "    plt.xticks(range(len(labels_axis)), labels_axis, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(labels_axis)), labels_axis)\n",
    "    for (i, j), z in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(z), ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QL66t2yblB3K",
   "metadata": {
    "id": "QL66t2yblB3K"
   },
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "P0LtS-URk_aJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0LtS-URk_aJ",
    "outputId": "0c49ad90-8a51-43ee-aeae-0ce4c432f95c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inferencia:   0%|                                                                                                                | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[llm_classify_one_zero] intento 1 falló: name 'client' is not defined\n",
      "[llm_classify_one_zero] intento 2 falló: name 'client' is not defined\n",
      "[llm_classify_one_zero] intento 3 falló: name 'client' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inferencia:   0%|                                                                                                                | 0/15 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 15\u001b[0m, in \u001b[0;36mllm_classify_one_zero\u001b[1;34m(texto, temperature, model, max_retries, sleep_base)\u001b[0m\n\u001b[0;32m     14\u001b[0m check_quota()\n\u001b[1;32m---> 15\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     17\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     18\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: SYSTEM_PROMPT},\n\u001b[0;32m     19\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_prompt},\n\u001b[0;32m     20\u001b[0m     ],\n\u001b[0;32m     21\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[0;32m     22\u001b[0m     response_format\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson_object\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# favorece JSON válido\u001b[39;00m\n\u001b[0;32m     23\u001b[0m )\n\u001b[0;32m     24\u001b[0m raw \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ==== Zero-shot ====\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m zero_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_zero_shot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEXT_COL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLABEL_COL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m acc_z  \u001b[38;5;241m=\u001b[39m accuracy_score(zero_df[LABEL_COL], zero_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_zero_shot\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m f1m_z  \u001b[38;5;241m=\u001b[39m f1_score(zero_df[LABEL_COL], zero_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_zero_shot\u001b[39m\u001b[38;5;124m\"\u001b[39m], average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[58], line 4\u001b[0m, in \u001b[0;36mrun_zero_shot\u001b[1;34m(df_in, text_col, label_col)\u001b[0m\n\u001b[0;32m      2\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m txt \u001b[38;5;129;01min\u001b[39;00m tqdm(df_in[text_col]\u001b[38;5;241m.\u001b[39mtolist(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZero-shot inferencia\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mllm_classify_one_zero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     preds\u001b[38;5;241m.\u001b[39mappend(out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m out_df \u001b[38;5;241m=\u001b[39m df_in\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[1;32mIn[55], line 43\u001b[0m, in \u001b[0;36mllm_classify_one_zero\u001b[1;34m(texto, temperature, model, max_retries, sleep_base)\u001b[0m\n\u001b[0;32m     41\u001b[0m         last_err \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[llm_classify_one_zero] intento \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m falló: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43msleep_base\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Falla definitiva\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: OOD_LABEL \u001b[38;5;28;01mif\u001b[39;00m ALLOW_OOD \u001b[38;5;28;01melse\u001b[39;00m random\u001b[38;5;241m.\u001b[39mchoice(labels_plus),\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence_0_5\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     55\u001b[0m }\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==== Zero-shot ====\n",
    "zero_df = run_zero_shot(test_sample, TEXT_COL, LABEL_COL)\n",
    "acc_z  = accuracy_score(zero_df[LABEL_COL], zero_df[\"pred_zero_shot\"])\n",
    "f1m_z  = f1_score(zero_df[LABEL_COL], zero_df[\"pred_zero_shot\"], average=\"macro\")\n",
    "print(f\"[Zero-shot] accuracy={acc_z:.4f} | macro-F1={f1m_z:.4f}\")\n",
    "print(classification_report(zero_df[LABEL_COL], zero_df[\"pred_zero_shot\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xYKtQfw_lFrs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "xYKtQfw_lFrs",
    "outputId": "1b8c721f-2b73-4d19-b5cc-5ba5c7717eab"
   },
   "outputs": [],
   "source": [
    "cm_z = confusion_matrix(zero_df[LABEL_COL], zero_df[\"pred_zero_shot\"], labels=labels_plus)\n",
    "plot_confusion(cm_z, labels_plus, \"Matriz de confusión — Zero-shot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NkkJvmLrlIyX",
   "metadata": {
    "id": "NkkJvmLrlIyX"
   },
   "source": [
    "### Few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5xxOLuM4lIQt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xxOLuM4lIQt",
    "outputId": "d58a8de2-f1ae-4791-dc29-a4cd69b55e2e"
   },
   "outputs": [],
   "source": [
    "# ==== Few-shot ====\n",
    "K_SHOTS = 3\n",
    "few_df = run_few_shot(train_df, test_sample, TEXT_COL, LABEL_COL, k_shots=K_SHOTS)\n",
    "acc_f  = accuracy_score(few_df[LABEL_COL], few_df[f\"pred_few_shot_k{K_SHOTS}\"])\n",
    "f1m_f  = f1_score(few_df[LABEL_COL], few_df[f\"pred_few_shot_k{K_SHOTS}\"], average=\"macro\")\n",
    "print(f\"[Few-shot k={K_SHOTS}] accuracy={acc_f:.4f} | macro-F1={f1m_f:.4f}\")\n",
    "print(classification_report(few_df[LABEL_COL], few_df[f\"pred_few_shot_k{K_SHOTS}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sBRzgWyzlM63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "sBRzgWyzlM63",
    "outputId": "f3235425-0818-4c10-857c-cc4e72ff5010"
   },
   "outputs": [],
   "source": [
    "cm_f = confusion_matrix(few_df[LABEL_COL], few_df[f\"pred_few_shot_k{K_SHOTS}\"], labels=labels_plus)\n",
    "plot_confusion(cm_f, labels_plus, f\"Matriz de confusión — Few-shot (k={K_SHOTS})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9e414",
   "metadata": {
    "id": "8cd9e414"
   },
   "source": [
    "\n",
    "## 12) Comparativa y análisis de desacuerdos\n",
    "\n",
    "Se contrasta Zero-shot vs Few-shot y se listan algunos casos donde discrepan para facilitar el **análisis cualitativo**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0de4443",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "f0de4443",
    "outputId": "60c288f5-973a-4e2f-fc54-b484c111b8e1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'few_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m compare_df \u001b[38;5;241m=\u001b[39m test_sample\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m compare_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_zero_shot\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m zero_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_zero_shot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 3\u001b[0m compare_df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_few_shot_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK_SHOTS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfew_df\u001b[49m[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred_few_shot_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK_SHOTS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      4\u001b[0m compare_df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'few_df' is not defined"
     ]
    }
   ],
   "source": [
    "compare_df = test_sample.copy().reset_index(drop=True)\n",
    "compare_df[\"pred_zero_shot\"] = zero_df[\"pred_zero_shot\"].values\n",
    "compare_df[f\"pred_few_shot_k{K_SHOTS}\"] = few_df[f\"pred_few_shot_k{K_SHOTS}\"].values\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g6b9YNvclUwV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "g6b9YNvclUwV",
    "outputId": "6127cdbf-1583-49c1-d136-def0394fafca"
   },
   "outputs": [],
   "source": [
    "def disagreement_sample(df_in: pd.DataFrame, n: int = 10) -> pd.DataFrame:\n",
    "    mask = df_in[\"pred_zero_shot\"] != df_in[f\"pred_few_shot_k{K_SHOTS}\"]\n",
    "    if mask.sum() == 0:\n",
    "        return pd.DataFrame(columns=[TEXT_COL, LABEL_COL, \"pred_zero_shot\", f\"pred_few_shot_k{K_SHOTS}\"])\n",
    "    return df_in[mask].sample(n=min(n, mask.sum()), random_state=RANDOM_SEED)[\n",
    "        [TEXT_COL, LABEL_COL, \"pred_zero_shot\", f\"pred_few_shot_k{K_SHOTS}\"]\n",
    "    ]\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"setting\": [\"Zero-shot\", f\"Few-shot (k={K_SHOTS})\"],\n",
    "    \"accuracy\": [acc_z, acc_f],\n",
    "    \"macro_f1\": [f1m_z, f1m_f],\n",
    "})\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-gdzWoQZlXUb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "-gdzWoQZlXUb",
    "outputId": "eaa6b3ee-2b12-4159-8fe0-e87ba41bff8e"
   },
   "outputs": [],
   "source": [
    "display(disagreement_sample(compare_df, n=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45658b8",
   "metadata": {
    "id": "f45658b8"
   },
   "source": [
    "\n",
    "## 13) Guardado de artefactos (CSV + figuras)\n",
    "\n",
    "Los resultados se guardan en `OUTPUT_DIR`. Si se trabaja en Colab con Google Drive montado, los archivos quedan disponibles en la carpeta de Drive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ffa16c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0ffa16c",
    "outputId": "0354c423-7aaa-4277-d66b-3504ff4f2ee6"
   },
   "outputs": [],
   "source": [
    "zero_csv = os.path.join(OUTPUT_DIR, \"predicciones_zero_shot.csv\")\n",
    "few_csv  = os.path.join(OUTPUT_DIR, f\"predicciones_few_shot_k{K_SHOTS}.csv\")\n",
    "\n",
    "zero_df.to_csv(zero_csv, index=False)\n",
    "few_df.to_csv(few_csv, index=False)\n",
    "\n",
    "print(\"Guardados:\")\n",
    "print(\" -\", zero_csv)\n",
    "print(\" -\", few_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6485c5",
   "metadata": {
    "id": "bb6485c5"
   },
   "source": [
    "\n",
    "## 14) Notas operativas y buenas prácticas\n",
    "\n",
    "- **Determinismo relativo**: con `temperature=0` se favorece consistencia, pero pequeñas variaciones pueden ocurrir.\n",
    "- **Costo y latencia**: `N_SAMPLE` y `MAX_CALLS` permiten limitar el gasto en prototipos; ampliar cuando se necesite evaluación completa.\n",
    "- **Trazabilidad**: usar claves de **Proyecto** (`sk-proj-...`) para agrupar en un Dashboard específico y facilitar monitoreo.\n",
    "- **Seguridad**: manejar el token vía variables de entorno; evitar guardarlo en texto plano.\n",
    "- **Transferencia**: mantener un vocabulario canónico de etiquetas y descripciones (`LABEL_DESCRIPTIONS`) para facilitar reutilización entre dominios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moarxn8ZojwB",
   "metadata": {
    "id": "moarxn8ZojwB"
   },
   "source": [
    "# Contrafactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805a33ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "805a33ca",
    "outputId": "911a3f43-41cb-49ad-f5bf-b0e8ca9ee2bf"
   },
   "outputs": [],
   "source": [
    "def llm_evaluate_counterfactual(original_text: str, flipped_text: str, transformation_type: str, explanation: str,\n",
    "                                temperature: float = 0.0, model: str = MODEL_NAME,\n",
    "                                max_retries: int = 3, sleep_base: float = 1.5):\n",
    "    \"\"\"\n",
    "    Evalúa una versión contrafactual de un texto usando Chat Completions.\n",
    "    Devuelve un dict con las evaluaciones y el raw JSON.\n",
    "    \"\"\"\n",
    "    system_prompt_cf = \"\"\"\n",
    "    Estás evaluando un texto contrafactual. El texto original y su contrafactual son proporcionados. El\n",
    "Estás evaluando una versión sintética de un texto. El mensaje sintético es una versión del original con el sentimiento invertido.\n",
    "Evalúa la calidad del mensaje sintético según cuatro criterios utilizando un rango de [0,1]:\n",
    "1. Fluidad - ¿El mensaje sintético es graticalmente correcto y puede leerse con facilidad?\n",
    "2. Naturalidad - ¿Suena creíble que lo haya escrito un humano?\n",
    "3. Claridad del cambio de sentimiento - ¿El sentimiento ha cambiado con respecto al original?\n",
    "4. Conservación del significado - ¿Se conserva el significado principal aparte del sentimiento?\n",
    "Devuelva SOLO este JSON:\n",
    "{\n",
    "\"fluidez\": 0 o 1,\n",
    "\"naturalidad\": 0 o 1,\n",
    "\"claridad_cambio_sentimiento\": 0 o 1,\n",
    "\"conservación_significado\": 0 o 1,\n",
    "\"comentario_annotador\": \"comentario opcional (string)\"\n",
    "}\n",
    "\"\"\".strip()\n",
    "\n",
    "    user_prompt_cf = f\"\"\"\n",
    "Mensaje Original: \"{original_text}\"\n",
    "Mensaje Sintético: \"{flipped_text}\"\n",
    "Transformation Type: {transformation_type}\n",
    "GPT-4 Explanation for the Flip: \"{explanation}\"\n",
    "\"\"\".strip()\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            check_quota()\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt_cf},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt_cf},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            raw = resp.choices[0].message.content\n",
    "            data = parse_json_strict(raw)\n",
    "            return {\n",
    "                \"fluidez\": data.get(\"fluidez\"),\n",
    "                \"naturalidad\": data.get(\"naturalidad\"),\n",
    "                \"claridad_cambio_sentimiento\": data.get(\"claridad_cambio_sentimiento\"),\n",
    "                \"conservación_significado\": data.get(\"conservación_significado\"),\n",
    "                \"comentario_annotador\": data.get(\"comentario_annotador\", \"\"),\n",
    "                \"raw\": data\n",
    "            }\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"[llm_evaluate_counterfactual] intento {attempt+1} falló: {e}\")\n",
    "            time.sleep(sleep_base * (2 ** attempt))\n",
    "\n",
    "    return {\n",
    "        \"fluidez\": None,\n",
    "        \"naturalidad\": None,\n",
    "        \"claridad_cambio_sentimiento\": None,\n",
    "        \"conservación_significado\": None,\n",
    "        \"comentario_annotador\": f\"fallback: {last_err}\",\n",
    "        \"raw\": None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776ff64-267f-475e-9c04-5bfad2c79996",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "4a54b837",
    "outputId": "273dc282-e166-467c-c929-04b5ff35b50b"
   },
   "outputs": [],
   "source": [
    "# Aplicar la evaluación contrafactual a cada fila de compare_df\n",
    "\n",
    "evaluation_results_zero_shot = []\n",
    "evaluation_results_few_shot = []\n",
    "\n",
    "# Iterar sobre las filas del DataFrame\n",
    "for index, row in tqdm(compare_df.iterrows(), total=len(compare_df), desc=\"Evaluando contrafactuales\"):\n",
    "    original_text = row[TEXT_COL]\n",
    "    # Evaluar Zero-shot prediction as the flipped text\n",
    "    flipped_text_zero = row[\"pred_zero_shot\"]\n",
    "    result_zero = llm_evaluate_counterfactual(\n",
    "        original_text=original_text,\n",
    "        flipped_text=flipped_text_zero,\n",
    "        transformation_type=\"Zero-shot Prediction\", # Puedes ajustar esto si tienes un tipo de transformación más específico\n",
    "        explanation=\"\" # La explicación puede ser vacía o basada en la justificación del modelo si la guardaste\n",
    "    )\n",
    "    evaluation_results_zero_shot.append(result_zero)\n",
    "\n",
    "    # Evaluar Few-shot prediction as the flipped text\n",
    "    flipped_text_few = row[f\"pred_few_shot_k{K_SHOTS}\"]\n",
    "    result_few = llm_evaluate_counterfactual(\n",
    "        original_text=original_text,\n",
    "        flipped_text=flipped_text_few,\n",
    "        transformation_type=f\"Few-shot Prediction (k={K_SHOTS})\", # Puedes ajustar esto\n",
    "        explanation=\"\" # La explicación puede ser vacía o basada en la justificación del modelo\n",
    "    )\n",
    "    evaluation_results_few_shot.append(result_few)\n",
    "\n",
    "\n",
    "# Convertir los resultados a DataFrames y unirlos al original\n",
    "eval_df_zero = pd.DataFrame(evaluation_results_zero_shot)\n",
    "eval_df_zero.columns = [f\"eval_zero_shot_{col}\" for col in eval_df_zero.columns]\n",
    "\n",
    "eval_df_few = pd.DataFrame(evaluation_results_few_shot)\n",
    "eval_df_few.columns = [f\"eval_few_shot_{col}\" for col in eval_df_few.columns]\n",
    "\n",
    "\n",
    "# Unir los resultados al DataFrame original (compare_df)\n",
    "# Usamos .copy() para evitar SettingWithCopyWarning\n",
    "compare_df_evaluated = compare_df.copy()\n",
    "compare_df_evaluated = pd.concat([compare_df_evaluated, eval_df_zero, eval_df_few], axis=1)\n",
    "\n",
    "# Mostrar el DataFrame con los resultados de la evaluación\n",
    "display(compare_df_evaluated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0220ee8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "id": "e0220ee8",
    "outputId": "208bb30e-eff5-4088-90f8-23c3195838bb"
   },
   "outputs": [],
   "source": [
    "# Ejemplo de uso de la función llm_evaluate_counterfactual\n",
    "\n",
    "# Datos de ejemplo (reemplaza con tus datos reales)\n",
    "original_text_example = \"Me encantó la película, fue muy emocionante.\"\n",
    "flipped_text_example = \"Odié la película, fue muy aburrida.\"\n",
    "transformation_type_example = \"Manual Sentiment Flip\"\n",
    "explanation_example = \"Se reemplazaron palabras positivas por antónimos negativos.\"\n",
    "\n",
    "# Llama a la función de evaluación\n",
    "evaluation_result = llm_evaluate_counterfactual(\n",
    "    original_text=original_text_example,\n",
    "    flipped_text=flipped_text_example,\n",
    "    transformation_type=transformation_type_example,\n",
    "    explanation=explanation_example\n",
    ")\n",
    "\n",
    "# Muestra el resultado de la evaluación\n",
    "print(\"Resultado de la evaluación contrafactual:\")\n",
    "display(evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T4TflTekICSM",
   "metadata": {
    "id": "T4TflTekICSM"
   },
   "source": [
    "esto se lo pedi a gemini jeje pero así da pauta de moverle ára el generation y el filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ByIr9Y19D5yg",
   "metadata": {
    "id": "ByIr9Y19D5yg"
   },
   "outputs": [],
   "source": [
    "def llm_generate_counterfactual(original_text: str, original_sentiment: str,\n",
    "                                temperature: float = 0.0, model: str = MODEL_NAME,\n",
    "                                max_retries: int = 3, sleep_base: float = 1.5):\n",
    "    \"\"\"\n",
    "    Generates counterfactual versions of a text with flipped sentiment using Chat Completions.\n",
    "    Returns a list of dicts with the counterfactual texts and explanations, and the raw JSON.\n",
    "    \"\"\"\n",
    "    system_prompt_cf_gen = \"\"\"\n",
    "    You are an NLP assistant helping researchers generate high-quality counterfactual examples for sentiment classification. Given a text and its sentiment (positive or negative), generate 3 distinct versions that flip the sentiment. Only modify necessary components. Preserve fluency and realism. Respect informal tone. You may flip sentiment by changing components such as: - keywords, phrases, negation, intent framing, tone (e.g., sarcasm), sentiment valence, emojis/icons, code-mixing.\n",
    "    Devuelva SOLO este JSON:\n",
    "    [\n",
    "      {{\n",
    "        \"cf_text\": \"...\",\n",
    "        \"components_changed\": [\"...\", \"...\"],\n",
    "        \"flip_explanation\": \"...\"\n",
    "      }},\n",
    "      {{\n",
    "        \"cf_text\": \"...\",\n",
    "        \"components_changed\": [\"...\", \"...\"],\n",
    "        \"flip_explanation\": \"...\"\n",
    "      }},\n",
    "      {{\n",
    "        \"cf_text\": \"...\",\n",
    "        \"components_changed\": [\"...\", \"...\"],\n",
    "        \"flip_explanation\": \"...\"\n",
    "      }}\n",
    "    ]\n",
    "    \"\"\".strip()\n",
    "\n",
    "    user_prompt_cf_gen = f\"\"\"\n",
    "    Input:\n",
    "    Original message: \"{original_text}\"\n",
    "    Original sentiment:\"{original_sentiment}\"\n",
    "    \"\"\".strip()\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            check_quota()\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt_cf_gen},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt_cf_gen},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            raw = resp.choices[0].message.content\n",
    "            data = parse_json_strict(raw) # Assuming parse_json_strict can handle a list of dicts\n",
    "            return {\n",
    "                \"counterfactuals\": data,\n",
    "                \"raw\": data\n",
    "            }\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"[llm_generate_counterfactual] intento {attempt+1} falló: {e}\")\n",
    "            time.sleep(sleep_base * (2 ** attempt))\n",
    "\n",
    "    return {\n",
    "        \"counterfactuals\": [],\n",
    "        \"raw\": None,\n",
    "        \"error\": f\"fallback: {last_err}\"\n",
    "    }\n",
    "\n",
    "# Example Usage (you can uncomment and run this to test the function)\n",
    "# original_text_gen_example = \"Me encantó la película, fue muy emocionante.\"\n",
    "# original_sentiment_gen_example = \"positive\"\n",
    "\n",
    "# generated_counterfactuals = llm_generate_counterfactual(\n",
    "#     original_text=original_text_gen_example,\n",
    "#     original_sentiment=original_sentiment_gen_example\n",
    "# )\n",
    "\n",
    "# print(\"\\nGenerated Counterfactuals:\")\n",
    "# display(generated_counterfactuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PcYfgKxUFCC6",
   "metadata": {
    "id": "PcYfgKxUFCC6"
   },
   "outputs": [],
   "source": [
    "def llm_filter_counterfactual(original_text: str, original_sentiment: str,\n",
    "                              cf_candidates: list[str],\n",
    "                              temperature: float = 0.0, model: str = MODEL_NAME,\n",
    "                              max_retries: int = 3, sleep_base: float = 1.5):\n",
    "    \"\"\"\n",
    "    Filters the best counterfactual from a list of candidates using Chat Completions.\n",
    "    Returns a dict with the selected counterfactual, justification, and predicted sentiment.\n",
    "    \"\"\"\n",
    "    system_prompt_cf_filter = \"\"\"\n",
    "    You are a sentiment evaluation assistant. Your task is to select the best counterfactual rewrite of a message.\n",
    "    RESPONSE FORMAT (JSON only):\n",
    "    {{\n",
    "    \"selected_cf\": \"...\",\n",
    "    \"justification\": \"...\",\n",
    "    \"predicted_sentiment\": \"Positive / Negative\"\n",
    "    }}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    cf_list_str = \"\\n\".join([f\"{i+1}. \\\"{cf}\\\"\" for i, cf in enumerate(cf_candidates)])\n",
    "\n",
    "    user_prompt_cf_filter = f\"\"\"\n",
    "    ORIGINAL MESSAGE\n",
    "    \"{original_text}\"\n",
    "    (Sentiment: {original_sentiment})\n",
    "\n",
    "    COUNTERFACTUAL CANDIDATES\n",
    "    {cf_list_str}\n",
    "\n",
    "    INSTRUCTIONS\n",
    "    Your goal is to identify which counterfactual most effectively flips the sentiment while remaining realistic and fluent.\n",
    "    - Flip sentiment plausibly\n",
    "    - Sound natural in social media comments\n",
    "    - Preserve meaning/context where possible\n",
    "    \"\"\".strip()\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            check_quota()\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt_cf_filter},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt_cf_filter},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            raw = resp.choices[0].message.content\n",
    "            data = parse_json_strict(raw)\n",
    "            return {\n",
    "                \"selected_cf\": data.get(\"selected_cf\"),\n",
    "                \"justification\": data.get(\"justification\"),\n",
    "                \"predicted_sentiment\": data.get(\"predicted_sentiment\"),\n",
    "                \"raw\": data\n",
    "            }\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            print(f\"[llm_filter_counterfactual] intento {attempt+1} falló: {e}\")\n",
    "            time.sleep(sleep_base * (2 ** attempt))\n",
    "\n",
    "    return {\n",
    "        \"selected_cf\": None,\n",
    "        \"justification\": f\"fallback: {last_err}\",\n",
    "        \"predicted_sentiment\": None,\n",
    "        \"raw\": None,\n",
    "    }\n",
    "\n",
    "# Example Usage (you can uncomment and run this to test the function)\n",
    "# original_text_filter_example = \"Me encantó la película, fue muy emocionante.\"\n",
    "# original_sentiment_filter_example = \"positive\"\n",
    "# cf_candidates_example = [\n",
    "#     \"Odié la película, fue muy aburrida.\",\n",
    "#     \"La película no estuvo tan buena como esperaba.\",\n",
    "#     \"Fue una pérdida de tiempo ver esa película.\"\n",
    "# ]\n",
    "\n",
    "# filtered_counterfactual = llm_filter_counterfactual(\n",
    "#     original_text=original_text_filter_example,\n",
    "#     original_sentiment=original_sentiment_filter_example,\n",
    "#     cf_candidates=cf_candidates_example\n",
    "# )\n",
    "\n",
    "# print(\"\\nFiltered Counterfactual:\")\n",
    "# display(filtered_counterfactual)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
